{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f42bcb99-54dc-43ae-807b-97f4c72d672a",
   "metadata": {},
   "source": [
    "# F3. Risk Scoring\n",
    "\n",
    ">>_The CSF’s use will vary based on an organization’s unique mission and risks. With an understanding of stakeholder expectations and risk appetite and tolerance (as outlined in GOVERN), an organization can prioritize cybersecurity activities to make informed decisions about cybersecurity expenditures and actions. An organization may choose to handle risk in one or more ways — including mitigating, transferring, avoiding, or accepting negative risks and realizing, sharing, enhancing, or accepting positive risks — depending on the potential impacts and likelihoods. Importantly, an organization can use the CSF both internally to manage its cybersecurity capabilities and externally to oversee or communicate with third parties._\\\n",
    "\\\n",
    "\\- _[National Institute of Standards and Technology (NIST)](https://nvlpubs.nist.gov/nistpubs/CSWP/NIST.CSWP.29.pdf)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c60ca933-e4a4-4e6c-a411-ec9c9c3a7aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Risk Philosophy</th>\n",
       "      <th>Scoring Formula(s)</th>\n",
       "      <th>Aggregation(s)</th>\n",
       "      <th>When to Use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Conservative</td>\n",
       "      <td>Multiplicative</td>\n",
       "      <td>Max</td>\n",
       "      <td>To only act on high-confidence, multi-dimensio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Worst-case</td>\n",
       "      <td>Worst Case (Max)</td>\n",
       "      <td>Max</td>\n",
       "      <td>To flag any asset with a single severe vulnera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Balanced/Pragmatic</td>\n",
       "      <td>Weighted Average, Simple Mean</td>\n",
       "      <td>Mean, Median</td>\n",
       "      <td>For realistic, overall asset risk monitoring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cumulative</td>\n",
       "      <td>Simple Mean, Weighted Average</td>\n",
       "      <td>Sum</td>\n",
       "      <td>When interested in total risk exposure per asset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Outlier-resistant</td>\n",
       "      <td>Simple Mean, Weighted Average</td>\n",
       "      <td>Median</td>\n",
       "      <td>To ignore rare extremes and focus on typical r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Risk Philosophy             Scoring Formula(s) Aggregation(s)  \\\n",
       "0        Conservative                 Multiplicative            Max   \n",
       "1          Worst-case               Worst Case (Max)            Max   \n",
       "2  Balanced/Pragmatic  Weighted Average, Simple Mean   Mean, Median   \n",
       "3          Cumulative  Simple Mean, Weighted Average            Sum   \n",
       "4   Outlier-resistant  Simple Mean, Weighted Average         Median   \n",
       "\n",
       "                                         When to Use  \n",
       "0  To only act on high-confidence, multi-dimensio...  \n",
       "1  To flag any asset with a single severe vulnera...  \n",
       "2       For realistic, overall asset risk monitoring  \n",
       "3   When interested in total risk exposure per asset  \n",
       "4  To ignore rare extremes and focus on typical r...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "philosophy = pd.read_csv('../data/risk_philosophy.csv')\n",
    "philosophy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c39eda-d2a5-4c2a-a900-9e5724b8801c",
   "metadata": {},
   "source": [
    "## Intended Purpose of Code\n",
    "\n",
    "The risk scoring module was designed with an interactive dashboard that generates personalized risk scoring and summarizes findings using tables and graphs to account for individual user needs. Some of the graphs are generated using data not involved in calculating risk scores and don't update with new user input. These graphs are 'static' and supplement findings in the risk score analysis.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "#### Risk-Scoring\n",
    "* Interactive risk scoring module with user input/dropdown/slider for:\n",
    "    * Risk Formula\n",
    "        * Supports multiple risk formulas (weighted, multiplicative, worst-case, mean)\n",
    "    * Aggregation Method\n",
    "        * Aggregates by (max, mean, median, sum, count high-risk CVEs)\n",
    "    * Floating Slider\n",
    "        * Allows users to toggle CVE count thresholds per asset\n",
    "\n",
    "#### Analysis & Visualization\n",
    "* Generates the following in response to user inputs in the interactive risk scoring module:\n",
    "    * Summary Tables\n",
    "        * Asset-level Risk Summary\n",
    "        * CVE-level Vulnerabilities Summary\n",
    "    * Heatmap\n",
    "        * asset vs riskScore\n",
    "    * Time Series:\n",
    "        * monthly count of new CVEs per asset\n",
    "            * Future Enhancement: multiple choice legend allowing users to filter any combination of assets\n",
    " \n",
    "\n",
    "#### Static Visualizations\n",
    "* Pie Chart\n",
    "    * distribution of severity levels (Critical/High/Medium/Low)\n",
    "\n",
    "### Known Issues\n",
    "\n",
    "* Save buttons overwrite existing files instead of saving a unique file\n",
    "    * Appending a version number to the end of the file with each click could resolve this\n",
    "* No way to sort summary tables\n",
    "    * _Needs more thought..._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f11f733-78a4-43a7-8ea7-aee5f961f697",
   "metadata": {},
   "source": [
    "_The interactive components of the below code were AI generated to tailor analysis to individual user needs._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1f3ddbd-72a2-44c9-9c3f-d69618a7cbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e204de53b6494be0a9b339ec93c6a52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Risk Formula:', options=('Weighted Average', 'Multiplicative', 'Wo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, FileLink\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import interact, Dropdown\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Helper Functions for Saving Tables and Charts ---\n",
    "def save_table_to_ass_csv(df, filename=\"../data/asset_risk_summary.csv\"):\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Table saved as '{filename}'\")\n",
    "    display(FileLink(filename))\n",
    "\n",
    "def save_table_to_vul_csv(df, filename=\"../data/cve_vuln_summary.csv\"):\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Table saved as '{filename}'\")\n",
    "    display(FileLink(filename))\n",
    "\n",
    "def add_ass_table_save_buttons(df, table_label=\"ass_table\"):\n",
    "    save_ass_csv_button = widgets.Button(description=f\"Save {table_label}\")\n",
    "    def on_save_ass_csv_clicked(b):\n",
    "        save_table_to_ass_csv(df, filename=\"../data/asset_risk_summary.csv\")\n",
    "    save_ass_csv_button.on_click(on_save_ass_csv_clicked)   # FIXED\n",
    "    display(save_ass_csv_button)\n",
    "    \n",
    "def add_vul_table_save_buttons(df, table_label=\"vul_table\"):\n",
    "    save_vul_csv_button = widgets.Button(description=f\"Save {table_label}\")\n",
    "    def save_vul_csv_clicked(b):\n",
    "        save_table_to_vul_csv(df, filename=\"../data/cve_vuln_summary.csv\")\n",
    "    save_vul_csv_button.on_click(save_vul_csv_clicked)       # FIXED\n",
    "    display(save_vul_csv_button)\n",
    "\n",
    "# Configuration\n",
    "input_file = \"../data/vuln_catalogue_v2.csv\"  # Change to your path if needed\n",
    "\n",
    "# Load Data\n",
    "def load_vuln_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "# --- RISK FORMULAS ---\n",
    "def weighted_average_score(row, weights=None):\n",
    "    if weights is None:\n",
    "        weights = {'baseScore': 0.5, 'exploitabilityScore': 0.25, 'impactScore': 0.25}\n",
    "    vals = [(row.get(col), w) for col, w in weights.items() if pd.notnull(row.get(col))]\n",
    "    if not vals:\n",
    "        return np.nan\n",
    "    score = sum(v * w for v, w in vals)\n",
    "    total_weight = sum(w for _, w in vals)\n",
    "    return round(score / total_weight, 2)\n",
    "\n",
    "def multiplicative_risk_score(row):\n",
    "    vals = [row.get(col) for col in ['baseScore', 'exploitabilityScore', 'impactScore']]\n",
    "    if any(pd.isnull(v) for v in vals):\n",
    "        return np.nan\n",
    "    vals_norm = [v / 10.0 for v in vals]\n",
    "    score = np.prod(vals_norm) * 10\n",
    "    return round(score, 2)\n",
    "\n",
    "def worst_case_score(row):\n",
    "    vals = [row.get(col) for col in ['baseScore', 'exploitabilityScore', 'impactScore']]\n",
    "    vals = [v for v in vals if pd.notnull(v)]\n",
    "    if not vals:\n",
    "        return np.nan\n",
    "    return max(vals)\n",
    "\n",
    "def simple_mean_score(row):\n",
    "    vals = [row.get(col) for col in ['baseScore', 'exploitabilityScore', 'impactScore']]\n",
    "    vals = [v for v in vals if pd.notnull(v)]\n",
    "    if not vals:\n",
    "        return np.nan\n",
    "    return round(np.mean(vals), 2)\n",
    "\n",
    "formula_map = {\n",
    "    'Weighted Average': weighted_average_score,\n",
    "    'Multiplicative': multiplicative_risk_score,\n",
    "    'Worst Case (Max)': worst_case_score,\n",
    "    'Simple Mean': simple_mean_score,\n",
    "}\n",
    "\n",
    "agg_map = {\n",
    "    'Max': 'max',\n",
    "    'Mean': 'mean',\n",
    "    'Median': 'median',\n",
    "    'Sum': 'sum',\n",
    "}\n",
    "\n",
    "def count_high_risk(series, threshold=7.0):\n",
    "    return (series >= threshold).sum()\n",
    "\n",
    "# Interactive Function\n",
    "def interactive_risk_scoring(input_file=input_file):\n",
    "    df = load_vuln_data(input_file)\n",
    "    for col in ['baseScore', 'exploitabilityScore', 'impactScore']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        else:\n",
    "            df[col] = np.nan\n",
    "    \n",
    "    def update_scoring(formula, aggregation, highrisk_threshold):\n",
    "        # Calculate riskScore\n",
    "        df['riskScore'] = df.apply(formula_map[formula], axis=1)\n",
    "        # Aggregate per asset (Title)\n",
    "        group = df.groupby(['Title','cpeName'])\n",
    "        agg_df = group['riskScore'].agg(agg_map[aggregation]).reset_index()\n",
    "        agg_df = agg_df.rename(columns={'riskScore': f'{aggregation}RiskScore'})\n",
    "        # Count high risk CVEs per asset\n",
    "        highrisk_df = group['riskScore'].apply(lambda x: (x >= highrisk_threshold).sum()).reset_index()\n",
    "        highrisk_df = highrisk_df.rename(columns={'riskScore': f'countHighRiskCVEs (>{highrisk_threshold})'})\n",
    "        # Merge for summary\n",
    "        summary = pd.merge(agg_df, highrisk_df, on='cpeName', how='left')\n",
    "        summary['Title']=summary['Title_x']\n",
    "        summary.drop(columns=['Title_x','Title_y'],inplace=True,axis=1)\n",
    "        summary.insert(0, \"Title\", summary.pop(\"Title\"))\n",
    "        # Show sample summary and first few vulnerabilities for inspection\n",
    "        print(\"\\nAsset-level Risk Summary:\")\n",
    "        display(summary.head(20))\n",
    "        add_ass_table_save_buttons(summary, table_label=\"Summary\")\n",
    "        print(\"\\nCVE-level Vulnerabilities Summary:\")\n",
    "        display(df[['Title', 'cveID', 'riskScore']].head(20))\n",
    "        add_vul_table_save_buttons(df[['Title','cpeName', 'cveID', 'riskScore']], table_label=\"Summary\")\n",
    "\n",
    "        # Pie Chart: Distribution of Severity Levels \n",
    "        severity_counts = df['baseSeverity'].value_counts()\n",
    "        severity_counts.plot(kind='pie', autopct='%1.1f%%', startangle=140, figsize=(6,6))\n",
    "        plt.title(\"Distribution of Severity Levels\")\n",
    "        plt.ylabel(\"\")\n",
    "        plt.show()\n",
    "    \n",
    "        # Heatmap: Top 20 Assets by selected risk score aggregation\n",
    "        top_assets = summary.sort_values(by=f'{aggregation}RiskScore', ascending=False).head(20)\n",
    "        heatmap_data = top_assets.set_index('Title')[[f'{aggregation}RiskScore']]\n",
    "        plt.figure(figsize=(2, 10))\n",
    "        sns.heatmap(heatmap_data, annot=True, cmap='YlOrRd', cbar=True)\n",
    "        plt.title(f\"Heatmap: Top 20 Assets by {aggregation} Risk Score\\n(Formula: {formula})\")\n",
    "        plt.xlabel(f\"{aggregation} Risk Score\")\n",
    "        plt.ylabel(\"Asset (Title)\")\n",
    "        plt.xticks(rotation=0)\n",
    "        plt.show()\n",
    "    \n",
    "        # Time Series: Monthly Count of New CVEs per Asset\n",
    "        if 'published' in df.columns:\n",
    "            df['published'] = pd.to_datetime(df['published'], errors='coerce')\n",
    "            df['month'] = df['published'].dt.to_period('M').astype(str)\n",
    "            df['year'] = df['published'].dt.year\n",
    "        else:\n",
    "            raise KeyError(\"No 'published' column found in DataFrame.\")\n",
    "    \n",
    "        asset_col = 'Title'\n",
    "    \n",
    "        def plot_monthly_cves(year_range):\n",
    "            min_year, max_year = year_range\n",
    "            df_filtered = df[(df['year'] >= min_year) & (df['year'] <= max_year)]\n",
    "            monthly_cves = df_filtered.groupby(['month', asset_col])['cveID'].nunique().unstack(fill_value=0)\n",
    "            if monthly_cves.empty:\n",
    "                print(f\"No data available for the selected year range: {min_year}-{max_year}\")\n",
    "                return\n",
    "            monthly_cves.plot(figsize=(14,7))\n",
    "            plt.title(f\"Monthly Count of New CVEs per Asset ({min_year}-{max_year})\")\n",
    "            plt.ylabel(\"Number of New CVEs\")\n",
    "            plt.xlabel(\"Month\")\n",
    "            plt.legend(title='Asset', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "        years = sorted(df['year'].dropna().unique())\n",
    "        if years:\n",
    "            year_slider = widgets.IntRangeSlider(\n",
    "                value=[min(years), max(years)],\n",
    "                min=min(years),\n",
    "                max=max(years),\n",
    "                step=1,\n",
    "                description='Year Range:',\n",
    "                continuous_update=False\n",
    "            )\n",
    "            out = widgets.interactive_output(plot_monthly_cves, {'year_range': year_slider})\n",
    "            display(year_slider, out)\n",
    "        else:\n",
    "            print(\"No valid years found in the data.\")\n",
    "    \n",
    "        return\n",
    "\n",
    "    interact(\n",
    "        update_scoring,\n",
    "        formula=Dropdown(options=list(formula_map.keys()), value='Weighted Average', description='Risk Formula:'),\n",
    "        aggregation=Dropdown(options=list(agg_map.keys()), value='Max', description='Aggregation:'),\n",
    "        highrisk_threshold=widgets.FloatSlider(value=7.0, min=0.0, max=10.0, step=0.1, description='High Risk CVE:')\n",
    "    )\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "if __name__ == \"__main__\":\n",
    "    interactive_risk_scoring(input_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
