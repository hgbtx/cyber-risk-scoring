{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed35d1d5-a0a8-4517-b0c1-d129b94232c7",
   "metadata": {},
   "source": [
    "# F1. Asset Inventory: Ingesting CPEs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "408804cf-ccb0-4560-ab1b-263714f66f29",
   "metadata": {},
   "source": [
    "Before CVEs can be ingested and processed for risk scoring, ``cpe_name``s must be identified and ingested as this is a required parameter when using the NVD CVE API. When no ``cpe_name`` is defined in the NVD CVE API call, all ``cpe_names`` are returned. \n",
    "\n",
    "## Scope Management\n",
    "\n",
    "For the purposes of managing the scope of this application tool: \n",
    "\n",
    "* It is important to note that each CPE is likely to have multiple CVEs.\n",
    "* In some cases, a CPE can have hundreds (100's) of CVEs\n",
    "    * especially if the CPE is associated with a well-established product (e.g. Windows products)\n",
    "* When saving CPEs to the ``cpe_whitelist.csv``, only save the CPEs necessary for inventorying assets\n",
    "    * improves overall application performance\n",
    "    * prevents system errors/disruptions\n",
    " \n",
    "## Keyword Search Tips\n",
    "\n",
    "Because this search engine is __not__ an exact keyword search, it is recommended that users:\n",
    "* start with vendor name only (e.g. Adobe)\n",
    "* refine search by adding product keyword (e.g. Acrobat)\n",
    "* further refine search by adding version number (e.g. 20.004.30006)\n",
    "\n",
    "## Intended Purpose of Code\n",
    "\n",
    "The below code was generated by AI to create a simple to use tool that interacts with the NVD CPE API.\n",
    "\n",
    "### Key features\n",
    "\n",
    "* User input to keyword search the CPE API\n",
    "* Machine outputs results\n",
    "* Prompts user with a yes/no/exit scenario before saving results to file\n",
    "* Saves search results to ``cpe_whitelist.csv``\n",
    "    * Does not overwrite previous outputs to file\n",
    "    * Appends new outputs to existing outputs in file\n",
    "* Undo write to file option\n",
    "    * user types 'undo' in the prompt\n",
    "    * removes most recent record written to file\n",
    "        * can be called repeatedly until no records written to file remain\n",
    "    * logs unwritten records in ``cpe_undo_log.csv``\n",
    "\n",
    "## Known Issues\n",
    "\n",
    "* There is no option to remove files out of this sequence.\n",
    "    * _For example, users cannot choose to unwrite a record in row 6 without unwriting every row after row 6 as well._\n",
    "* Search results cannot always be refined down to just one (1) ``cpe_name`` in scenarios where there are many ``cpe_name``s and the user wants to save a ``cpe_name`` with the broadest features.\n",
    "    * For example:\n",
    "        * a user key word searches 'Microsoft Exchange Server 2019'\n",
    "            * the CPE API returns 15 matches that includes\n",
    "                *    Title: Microsoft Exchange Server 2019\\\n",
    "                     \\- CPE Name: cpe:2.3:a:microsoft:exchange_server:2019:-:\\*:\\*:\\*:\\*:\\*:*\n",
    "            * all 14 cumulative updates of Microsoft Exchange Server 2019\n",
    "                *    Title: Microsoft Exchange Server 2019 Cumulative Update \\[1-14]\\\n",
    "                     \\- CPE Name: cpe:2.3:a:microsoft:exchange_server:2019:cumulative_update_\\[1-14]:\\*:\\*:\\*:\\*:\\*:*\\\n",
    "                     ![image.png](../img/f1_knownissue.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0399b9cb-fee8-4195-bed7-7d523b95d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, time, requests, os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# --- config -----------------------------------------------------------\n",
    "api_url = \"https://services.nvd.nist.gov/rest/json/cpes/2.0\"\n",
    "api_key = os.getenv(\"NVD_api_key\")\n",
    "rate_secs = 1.2\n",
    "whitelist = Path(\"../data/cpe_whitelist.csv\")\n",
    "header = ['WrittenAt', 'Title', 'cpeName']\n",
    "UNDO_LOG = Path(\"../data/cpe_undo_log.csv\")\n",
    "undo_header = ['UnwrittenAt', 'Title', 'cpeName']\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def search_cpe_names(keyword):\n",
    "    all_results = []\n",
    "    start_index = 0\n",
    "    results_per_page = 100\n",
    "    headers = {\"apiKey\": api_key}\n",
    "    while True:\n",
    "        params = {\n",
    "            \"keywordSearch\": keyword,\n",
    "            \"resultsPerPage\": results_per_page,\n",
    "            \"startIndex\": start_index\n",
    "        }\n",
    "        response = requests.get(api_url, params=params, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error fetching data for '{keyword}': {response.status_code} - {response.text}\")\n",
    "            break\n",
    "        data = response.json()\n",
    "        cpe_matches = data.get('products', [])\n",
    "        if not cpe_matches:\n",
    "            break\n",
    "        for item in cpe_matches:\n",
    "            metadata = item.get('cpe', {}).get('titles', [])\n",
    "            title = next((t['title'] for t in metadata if t.get('lang') == 'en'), metadata[0]['title'] if metadata else '')\n",
    "            cpe_uri = item.get('cpe', {}).get('cpeName', '')\n",
    "            if cpe_uri:\n",
    "                all_results.append({'title': title, 'cpeName': cpe_uri})\n",
    "        total_results = data.get('totalResults', 0)\n",
    "        start_index += results_per_page\n",
    "        if start_index >= total_results:\n",
    "            break\n",
    "        time.sleep(rate_secs)\n",
    "    return all_results\n",
    "\n",
    "def write_entries_to_csv(entries, path, header):\n",
    "    write_header = not path.exists() or os.path.getsize(path) == 0\n",
    "    now = datetime.now().isoformat(timespec='milliseconds')\n",
    "    rows_to_write = [[now, e['title'], e['cpeName']] for e in entries]\n",
    "    with open(path, \"a\", newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        if write_header:\n",
    "            writer.writerow(header)\n",
    "        writer.writerows(rows_to_write)\n",
    "    return now, len(rows_to_write)\n",
    "\n",
    "def log_removal_to_undo_log(removed_rows, undo_log, undo_header):\n",
    "    undo_write_header = not undo_log.exists() or os.path.getsize(undo_log) == 0\n",
    "    now = datetime.now().isoformat(timespec='milliseconds')\n",
    "    rows_to_log = [[now, title, cpename] for _, title, cpename in removed_rows]\n",
    "    with open(undo_log, \"a\", newline='', encoding='utf-8') as undofile:\n",
    "        undowriter = csv.writer(undofile)\n",
    "        if undo_write_header:\n",
    "            undowriter.writerow(undo_header)\n",
    "        undowriter.writerows(rows_to_log)\n",
    "\n",
    "def undo_last_write(path, header, undo_log, undo_header):\n",
    "    # Remove last batch of rows from whitelist and record them in undo log with UnwrittenAt\n",
    "    with open(path, \"r\", encoding='utf-8') as infile:\n",
    "        lines = list(csv.reader(infile))\n",
    "    if lines and lines[0] == header:\n",
    "        header_row = lines[0]\n",
    "        data_rows = lines[1:]\n",
    "    else:\n",
    "        header_row = header\n",
    "        data_rows = lines\n",
    "    if not data_rows:\n",
    "        print(\"No record(s) found.\")\n",
    "        return\n",
    "    # Find the most recent WrittenAt timestamp (last batch)\n",
    "    last_written_at = data_rows[-1][0]\n",
    "    rows_to_remove = [row for row in data_rows if row[0] == last_written_at]\n",
    "    if not rows_to_remove:\n",
    "        print(\"No record batch found.\")\n",
    "        return\n",
    "    # Remove these rows from data_rows\n",
    "    remaining_rows = [row for row in data_rows if row[0] != last_written_at]\n",
    "    with open(path, \"w\", newline='', encoding='utf-8') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(header_row)\n",
    "        writer.writerows(remaining_rows)\n",
    "    # Log these removals to undo log with UnwrittenAt\n",
    "    log_removal_to_undo_log(rows_to_remove, undo_log, undo_header)\n",
    "    print(f\"Undid last write: removed {len(rows_to_remove)} rows and logged them to the undo log.\")\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        user_input = input(\"Enter keywords, or type 'undo' to undo last write, or 'exit': \").strip()\n",
    "        if user_input.lower() in (\"exit\", \"e\"):\n",
    "            print(\"Exiting program. Goodbye!\")\n",
    "            break\n",
    "        if user_input.lower() == \"undo\":\n",
    "            undo_last_write(whitelist, header, UNDO_LOG, undo_header)\n",
    "            continue\n",
    "        search_keywords = [kw.strip() for kw in user_input.split(',')]\n",
    "        print(\"Search Keywords:\", search_keywords)\n",
    "        all_results = []\n",
    "        for keyword in search_keywords:\n",
    "            if keyword.lower() in (\"exit\", \"e\"):\n",
    "                print(\"Exiting program. Goodbye!\")\n",
    "                return\n",
    "            time.sleep(rate_secs)\n",
    "            matches = search_cpe_names(keyword)\n",
    "            print(f\"Number of matching results: {len(matches)}\")\n",
    "            print(f\"\\nMatches for '{keyword}':\")\n",
    "            if matches:\n",
    "                for match in matches:\n",
    "                    print(f\"   Title: {match['title']}\")\n",
    "                    print(f\" - CPE Name: {match['cpeName']}\")\n",
    "            else:\n",
    "                print(\"No matches found.\")\n",
    "            all_results.extend(matches)\n",
    "        if all_results:\n",
    "            while True:\n",
    "                save_input = input(f\"\\nDo you want to save {len(all_results)} results to file? (yes/no/exit): \").strip().lower()\n",
    "                if save_input in (\"yes\", \"y\"):\n",
    "                    now, nrows = write_entries_to_csv(all_results, whitelist, header)\n",
    "                    print(f\"\\n{nrows} results appended to {whitelist.resolve()} at {now}\")\n",
    "                    break\n",
    "                elif save_input in (\"no\", \"n\"):\n",
    "                    print(\"\\nYou chose not to save. Please enter new keywords.\")\n",
    "                    break\n",
    "                elif save_input in (\"exit\", \"e\"):\n",
    "                    print(\"Exiting program. Goodbye!\")\n",
    "                    return\n",
    "                else:\n",
    "                    print(\"Invalid input. Please enter 'yes', 'no', or 'exit'.\")\n",
    "        else:\n",
    "            print(\"\\nNo results to save. Please enter new keywords.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c204c-640f-4fa3-b1df-8b5b897880c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
